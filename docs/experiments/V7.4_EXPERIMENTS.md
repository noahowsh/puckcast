# V7.4 Experiment Log

> **Goal**: Improve from V7.3's 60.49% to 62%+ accuracy
> **Gap to close**: +1.51pp minimum

---

## Experiment 1: LightGBM Default Regularization

**Date**: December 5, 2025
**Status**: FAILED
**Script**: `training/train_v7_4_lightgbm.py`

### Hypothesis
LightGBM can capture non-linear feature interactions that LogReg cannot.

### Configuration
```python
configs = [
    {"n_estimators": 100, "max_depth": 4, "learning_rate": 0.1, "num_leaves": 15},
    {"n_estimators": 200, "max_depth": 5, "learning_rate": 0.05, "num_leaves": 31},
    {"n_estimators": 300, "max_depth": 6, "learning_rate": 0.03, "num_leaves": 31},  # Best CV
    {"n_estimators": 500, "max_depth": 4, "learning_rate": 0.02, "num_leaves": 15},
]
# Common params: min_child_samples=20, subsample=0.8, colsample_bytree=0.8
```

### Results

| Metric | V7.3 LogReg | V7.4 LightGBM | Difference |
|--------|-------------|---------------|------------|
| Accuracy | 60.49% | 57.15% | **-3.34pp** |
| Log Loss | 0.6702 | 0.7023 | +0.0321 (worse) |
| ROC-AUC | 0.6402 | 0.5931 | -0.0471 (worse) |
| Brier Score | ~0.237 | 0.2517 | +0.0147 (worse) |

### Cross-Validation Results
- Config 1: CV 57.76% (+/- 1.44%)
- Config 2: CV 58.82% (+/- 0.83%)
- Config 3: CV 58.94% (+/- 1.27%) <- Selected
- Config 4: CV 58.78% (+/- 0.90%)

### Confidence Buckets
| Grade | Games | Accuracy |
|-------|-------|----------|
| A+ | 228 | 66.2% |
| A- | 108 | 59.3% |
| B+ | 128 | 56.2% |
| B- | 110 | 53.6% |
| C | 130 | 56.2% |

### Top Features (LightGBM Importance)
1. shotsAgainst_roll_5_diff (149)
2. elo_diff_pre (143)
3. rolling_xg_against_3_diff (127)
4. rolling_xg_diff_3_diff (126)
5. season_win_pct_diff (119)

### Analysis
**Why it failed**:
1. **Overfitting**: CV showed 58.9% but test dropped to 57.15%
2. **Weak regularization**: Default LightGBM params don't prevent overfitting
3. **LogReg advantage**: C=0.05 provides strong L2 regularization that handles noisy NHL data

**Key insight**: NHL game prediction is inherently noisy. Gradient boosting without aggressive regularization will overfit to noise patterns in training data.

---

## Experiment 2: Heavily Regularized LightGBM

**Date**: December 5, 2025
**Status**: COMPLETED - Improved but still below V7.3
**Script**: `training/train_v7_4_lightgbm_regularized.py`

### Hypothesis
LightGBM with much stronger regularization (matching LogReg's C=0.05 effect) can avoid overfitting.

### Configurations Tested
| Config | max_depth | lr | leaves | min_leaf | reg_alpha | reg_lambda |
|--------|-----------|-----|--------|----------|-----------|------------|
| Ultra-Conservative | 2 | 0.005 | 4 | 200 | 2.0 | 2.0 |
| Very Conservative | 3 | 0.01 | 8 | 100 | 1.0 | 1.0 |
| Conservative | 4 | 0.02 | 15 | 50 | 0.5 | 0.5 |
| Moderate | 5 | 0.03 | 20 | 30 | 0.1 | 0.1 |

### Results

| Config | Val Acc | Test Acc | vs V7.3 |
|--------|---------|----------|---------|
| Ultra-Conservative | 58.54% | 59.35% | -1.14pp |
| Very Conservative | 57.11% | 59.76% | -0.73pp |
| **Conservative** | 57.72% | **59.92%** | **-0.57pp** |
| Moderate | 58.33% | 59.02% | -1.47pp |

**Best Result**: Conservative config at 59.92%
- Log Loss: 0.6679 (better than V7.3's 0.6702!)
- ROC-AUC: 0.6269

### Analysis
- Regularization prevented overfitting (+2.77pp vs Exp 1's 57.15%)
- Still can't match LogReg's accuracy
- Log-loss actually improved slightly

---

## Experiment 3: Ensemble (LogReg + LightGBM)

**Date**: December 5, 2025
**Status**: COMPLETED - Small improvement found
**Script**: `training/train_v7_4_ensemble.py`

### Hypothesis
Blending LogReg (good calibration) with regularized tree (non-linear patterns) improves accuracy.

### Weights Tested
| Blend | Accuracy | vs V7.3 |
|-------|----------|---------|
| 100% LogReg | 60.49% | 0.00pp |
| **90% LR + 10% LGBM** | **60.57%** | **+0.08pp** |
| 80% LR + 20% LGBM | 60.49% | 0.00pp |
| 70% LR + 30% LGBM | 60.57% | +0.08pp |
| 60% LR + 40% LGBM | 60.49% | 0.00pp |
| 50% LR + 50% LGBM | 60.08% | -0.41pp |
| 100% LGBM | 57.89% | -2.60pp |

### Best Result
- **90% LogReg + 10% LightGBM: 60.57%** (+0.08pp)
- Log Loss: **0.6669** (improved from 0.6702)
- ROC-AUC: **0.6414** (improved from 0.6402)
- A+ Bucket: **72.6%** (improved from ~71.5%)

### Model Correlation
- Correlation: 0.7678 (fairly high - models agree often)
- Disagreements: 266 games (21.6%)
- Ensemble accuracy on disagreements: 56.4%

### Analysis
- Small accuracy gain (+0.08pp) but improved log-loss and A+ bucket
- High model correlation limits ensemble benefit
- LightGBM adds marginal value at low weight

---

## Experiment 4: XGBoost with Strong Regularization

**Date**: December 5, 2025
**Status**: COMPLETED - Best ensemble found!
**Script**: `training/train_v7_4_xgboost.py`

### XGBoost Configurations Tested
| Config | max_depth | lr | min_child_weight | gamma | reg_alpha | reg_lambda |
|--------|-----------|-----|------------------|-------|-----------|------------|
| Very Strong | 2 | 0.01 | 50 | 1.0 | 1.0 | 2.0 |
| **Strong** | **3** | **0.02** | **30** | **0.5** | **0.5** | **1.0** |
| Moderate | 4 | 0.03 | 20 | 0.2 | 0.2 | 0.5 |
| Light | 5 | 0.05 | 10 | 0.1 | 0.1 | 0.2 |

### XGBoost Standalone Results
| Config | Val Acc | Test Acc | vs V7.3 |
|--------|---------|----------|---------|
| Very Strong | 58.54% | 59.67% | -0.82pp |
| **Strong** | **59.55%** | **60.24%** | **-0.25pp** |
| Moderate | 59.96% | 57.89% | -2.60pp |
| Light | 59.96% | 55.93% | -4.56pp |

### Ensemble Results (LogReg + XGBoost)
| Blend | Accuracy | vs V7.3 | Log Loss | ROC-AUC |
|-------|----------|---------|----------|---------|
| 95% LR + 5% XGB | 60.57% | +0.08pp | 0.6685 | 0.6411 |
| 92% LR + 8% XGB | 60.73% | +0.24pp | 0.6675 | 0.6414 |
| 90% LR + 10% XGB | 60.81% | +0.32pp | 0.6670 | 0.6415 |
| 88% LR + 12% XGB | 60.73% | +0.24pp | 0.6664 | 0.6417 |
| 85% LR + 15% XGB | 60.73% | +0.24pp | 0.6656 | 0.6421 |
| **80% LR + 20% XGB** | **60.98%** | **+0.49pp** | **0.6645** | **0.6425** |

### Best Model: 80% LogReg + 20% XGBoost

**Test Set Performance (1,230 games):**
- Accuracy: **60.98%** (+0.49pp over V7.3)
- Log Loss: **0.6645** (improved from 0.6702)
- ROC-AUC: **0.6425** (improved from 0.6402)
- Brier Score: **0.2357** (improved from ~0.237)

**Confidence Buckets:**
| Grade | Games | Accuracy |
|-------|-------|----------|
| A+ | 228 | **72.4%** |
| A- | 112 | 64.3% |
| B+ | 111 | 63.1% |
| B- | 128 | 53.9% |
| C | 136 | 52.9% |

---

## Summary Table

| Experiment | Accuracy | vs V7.3 | Log Loss | Status |
|------------|----------|---------|----------|--------|
| V7.3 LogReg (baseline) | 60.49% | - | 0.6702 | Previous Production |
| Exp 1: LightGBM default | 57.15% | -3.34pp | 0.7023 | FAILED |
| Exp 2: LightGBM regularized | 59.92% | -0.57pp | 0.6679 | Improved |
| Exp 3: Ensemble LR+LGBM | 60.57% | +0.08pp | 0.6669 | Small gain |
| Exp 4: XGBoost Strong | 60.24% | -0.25pp | 0.6712 | Baseline |
| **Exp 4: Ensemble LR+XGB** | **60.98%** | **+0.49pp** | **0.6645** | **NEW BEST** |

---

## Learnings

1. **Regularization is critical** - LogReg's C=0.05 is doing a lot of heavy lifting
2. **CV != Test performance** - Gap between CV (58.9%) and test (57.15%) indicates overfitting
3. **NHL prediction is noisy** - Tree models memorize noise without strong regularization
4. **XGBoost ensembles better than LightGBM** - 80/20 LR+XGB outperforms 90/10 LR+LGBM
5. **Log-loss improves more easily** - All regularized approaches improved log-loss
6. **Ensemble sweet spot around 80/20** - Too much tree weight hurts performance
